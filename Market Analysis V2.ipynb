{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ae2ea91a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2ea91a",
        "outputId": "342ee0fb-680a-41c1-ac43-7c962e9c3c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import Dict, Optional, List\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_lookup = pd.read_csv(\"/content/drive/Shareddrives/market_analysis_v2/gen_lookup.csv\")"
      ],
      "metadata": {
        "id": "J37vmfyrnkAQ"
      },
      "id": "J37vmfyrnkAQ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f818106"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "# ---------- Constants for CS (Carsales/General Scrapes) ----------\n",
        "YEAR_MIN, YEAR_MAX = 1980, 2035\n",
        "ORDER: List[str] = ['href', 'year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']\n",
        "\n",
        "YEAR_RE  = r'\\b(19[89]\\d|20[0-3]\\d)\\b'\n",
        "PRICE_RE = r'^\\s*\\$\\s*[\\d,]+(?:\\.\\d{2})?\\b'\n",
        "ODOM_RE  = r'^\\s*\\d{1,3}(?:,\\d{3})+\\s*km\\s*$'\n",
        "URL_RE   = r'^(?:https?://|www\\.)'\n",
        "TX, SELLER = {'automatic', 'manual'}, {'private', 'dealer used'}\n",
        "\n",
        "THRESH: Dict[str, float] = {\n",
        "    'year_make_model': 0.50,\n",
        "    \"listed_price\":           0.60,\n",
        "    'transmission':    0.80,\n",
        "    'odometer':        0.60,\n",
        "    'seller_type':     0.70,\n",
        "}\n",
        "\n",
        "# ---------- Constants for FB (Facebook Marketplace Scrapes) ----------\n",
        "FB_ORDER: List[str] = ['href', 'year_make_model', 'listed_price', 'odometer', 'location']\n",
        "# THRESH_FB values are used for identifying FB specific columns.\n",
        "# 'href' and 'year_make_model' are critical for data structuring.\n",
        "# 'listed_price' and 'odometer' are numeric and generally have clear patterns.\n",
        "# 'location' is the hardest to identify solely by content, so it has a lower threshold\n",
        "# and is often inferred from remaining columns or specific column names like 'c'.\n",
        "THRESH_FB: Dict[str, float] = {\n",
        "    'href':            0.80,\n",
        "    'year_make_model': 0.50,\n",
        "    'listed_price':    0.60,\n",
        "    'odometer':        0.60,\n",
        "    'location':        0.40,\n",
        "}\n",
        "\n",
        "# ---------- Predicates ----------\n",
        "def _ratio(mask: pd.Series) -> float:\n",
        "    return float(mask.mean()) if len(mask) else 0.0\n",
        "\n",
        "def _yr_ok(s: pd.Series) -> pd.Series:\n",
        "    years = pd.to_numeric(s.astype(str).str.extract(YEAR_RE, expand=False), errors='coerce')\n",
        "    return years.between(YEAR_MIN, YEAR_MAX)\n",
        "\n",
        "PRED = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    \"listed_price\":           lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'transmission':    lambda s: s.astype(str).str.strip().str.lower().isin(TX),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "    'seller_type':     lambda s: s.astype(str).str.strip().str.lower().isin(SELLER),\n",
        "}\n",
        "\n",
        "PRED_FB = {\n",
        "    'href':            lambda s: s.astype(str).str.contains(URL_RE, case=False, na=False),\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    'listed_price':    lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "}\n",
        "\n",
        "# ---------- Core Identification Functions ----------\n",
        "def identify_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical Carsales/General column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in ORDER}\n",
        "\n",
        "    href_col = cols[0]\n",
        "\n",
        "    # exclude URL-like columns from other detection\n",
        "    url_ratio = {c: _ratio(df[c].astype(str).str.contains(URL_RE, case=False, na=False)) for c in cols}\n",
        "    urlish = {c for c, r in url_ratio.items() if r >= 0.50}\n",
        "    blocked = {href_col} | urlish\n",
        "\n",
        "    remaining = [c for c in cols if c not in blocked]\n",
        "    picks = {t: None for t in PRED}\n",
        "\n",
        "    for t in PRED:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED[t](df[c])) for c in remaining}\n",
        "        best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "        if best_score >= THRESH[t]:\n",
        "            picks[t] = best_col\n",
        "            remaining.remove(best_col)\n",
        "\n",
        "    trim_col = None\n",
        "    ymm = picks.get('year_make_model')\n",
        "    if ymm in cols:\n",
        "        i = cols.index(ymm)\n",
        "        if i + 1 < len(cols):\n",
        "            trim_col = cols[i + 1]\n",
        "\n",
        "    return {'href': href_col, **picks, 'trim': trim_col}\n",
        "\n",
        "def identify_fb_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical Facebook Marketplace column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in FB_ORDER}\n",
        "\n",
        "    picks = {t: None for t in FB_ORDER}\n",
        "    remaining = set(cols)\n",
        "\n",
        "    # Prioritize 'href'\n",
        "    href_scores = {c: _ratio(PRED_FB['href'](df[c])) for c in remaining}\n",
        "    best_href_col, best_href_score = None, 0.0\n",
        "    if href_scores:\n",
        "        best_href_col, best_href_score = max(href_scores.items(), key=lambda kv: kv[1])\n",
        "\n",
        "    if best_href_score >= THRESH_FB['href']:\n",
        "        picks['href'] = best_href_col\n",
        "        remaining.remove(best_href_col)\n",
        "    elif 'x1i10hfl href' in remaining and _ratio(PRED_FB['href'](df['x1i10hfl href'])) >= THRESH_FB['href']:\n",
        "        # Fallback to specific column name if it exists and matches pattern well\n",
        "        picks['href'] = 'x1i10hfl href'\n",
        "        remaining.remove('x1i10hfl href')\n",
        "\n",
        "\n",
        "    # Identify 'year_make_model', 'listed_price', 'odometer'\n",
        "    for t in ['year_make_model', 'listed_price', 'odometer']:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED_FB[t](df[c])) for c in remaining}\n",
        "        if scores:\n",
        "            best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "            if best_score >= THRESH_FB[t]:\n",
        "                picks[t] = best_col\n",
        "                remaining.remove(best_col)\n",
        "\n",
        "    # Assign 'location'\n",
        "    if picks['location'] is None:\n",
        "        if 'c' in remaining: # The common FB Marketplace location column name\n",
        "            picks['location'] = 'c'\n",
        "            remaining.remove('c')\n",
        "        elif len(remaining) == 1: # If only one column left, it's likely location\n",
        "            picks['location'] = remaining.pop()\n",
        "\n",
        "    return picks\n",
        "\n",
        "\n",
        "# ---------- Cleaning Functions ----------\n",
        "def clean_cs(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Detect, rename, clean numeric/text data, and return standardized columns.\"\"\"\n",
        "    mapping = identify_columns(df)\n",
        "    out = pd.DataFrame()\n",
        "\n",
        "    # Map columns\n",
        "    if mapping['href'] is not None:\n",
        "        out['href'] = df[mapping['href']]\n",
        "    for col in ['year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']:\n",
        "        src = mapping.get(col)\n",
        "        if src is not None:\n",
        "            out[col] = df[src]\n",
        "\n",
        "    # Split \"year make model\"\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_cols = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        split_cols.columns = ['year', 'make', 'model']\n",
        "        out = pd.concat([out, split_cols], axis=1)\n",
        "\n",
        "    # Clean hrefs (remove query strings)\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    # Clean numeric columns\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            out[col] = (\n",
        "                out[col].astype(str)\n",
        "                .replace(r'[^\\d]', '', regex=True) # Corrected regex\n",
        "                .replace('', pd.NA)\n",
        "                .astype(float)\n",
        "                .astype('Int64')\n",
        "            )\n",
        "\n",
        "    # Convert odometer to thousands of km\n",
        "    if 'odometer' in out.columns:\n",
        "        out['odometer'] = out['odometer'] // 1000\n",
        "\n",
        "    # Build final tidy table\n",
        "    final_cols = ['href', 'year', 'make', 'model', \"listed_price\", 'trim', 'odometer', 'seller_type']\n",
        "    return out[[c for c in final_cols if c in out.columns]]\n",
        "\n",
        "def clean_fb(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Detect, rename, clean numeric/text data, and return standardized columns for Facebook Marketplace.\"\"\"\n",
        "    mapping = identify_fb_columns(df)\n",
        "    out = pd.DataFrame() # Initialize an empty DataFrame to store cleaned data\n",
        "\n",
        "    # Map columns based on identified mapping\n",
        "    # Only create columns in 'out' if they were successfully mapped and exist in original df\n",
        "    for canonical_col, src_col in mapping.items():\n",
        "        if src_col is not None and src_col in df.columns:\n",
        "            out[canonical_col] = df[src_col]\n",
        "\n",
        "    # Split the year_make_model column into 'year', 'make', 'model'\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_df = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        # Assign split parts to new columns, handling cases where parts might be missing\n",
        "        out['year'] = split_df[0] if 0 in split_df.columns else pd.NA\n",
        "        out['make'] = split_df[1] if 1 in split_df.columns else pd.NA\n",
        "        out['model'] = split_df[2] if 2 in split_df.columns else pd.NA\n",
        "    else:\n",
        "        # If 'year_make_model' was not found, initialize year/make/model to NA\n",
        "        out[['year', 'make', 'model']] = pd.NA\n",
        "\n",
        "    # Clean hrefs (remove query strings)\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    # Clean numeric columns: listed_price, odometer\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            # Handle 'Free' for listed_price specifically before conversion\n",
        "            if col == 'listed_price':\n",
        "                out = out[out[col].astype(str).str.lower() != \"free\"]\n",
        "\n",
        "            out[col] = (\n",
        "                out[col].astype(str)\n",
        "                .replace(r'[^\\d]', '', regex=True) # Remove non-digit characters\n",
        "                .replace('', pd.NA) # Replace empty strings with NA\n",
        "                .astype(float) # Convert to float first to handle NA\n",
        "                .astype('Int64') # Convert to nullable integer type\n",
        "            )\n",
        "\n",
        "    # Removing listings with null values for essential columns\n",
        "    cols_to_check_for_na = []\n",
        "    if 'listed_price' in out.columns: cols_to_check_for_na.append('listed_price')\n",
        "    if 'odometer' in out.columns: cols_to_check_for_na.append('odometer')\n",
        "    if 'year' in out.columns: cols_to_check_for_na.append('year')\n",
        "\n",
        "    if cols_to_check_for_na:\n",
        "        out = out.dropna(subset=cols_to_check_for_na)\n",
        "\n",
        "    # Remove crashed listings (magic numbers, ideally these would be parameters)\n",
        "    if 'listed_price' in out.columns:\n",
        "        out = out[out[\"listed_price\"] != 1234]\n",
        "        out = out[out[\"listed_price\"] != 12345]\n",
        "\n",
        "    # Select only the required columns in order\n",
        "    final_columns = ['href', 'year', 'make', 'model', \"listed_price\", 'odometer', 'location']\n",
        "    return out[[c for c in final_columns if c in out.columns]]\n",
        "\n",
        "def enrich_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Final clean after clean_cs or clean_fb.\"\"\"\n",
        "\n",
        "    # --- 1. Add date_scraped ---\n",
        "    df[\"date_scraped\"] = pd.Timestamp.now().normalize()\n",
        "\n",
        "    # --- 2. Normalise make & model ---\n",
        "    for col in [\"make\", \"model\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = (\n",
        "                df[col]\n",
        "                .astype(str)\n",
        "                .str.lower()\n",
        "                .str.replace(r\"[^a-z0-9]+\", \"\", regex=True)\n",
        "            )\n",
        "\n",
        "    # --- 3. Ensure year is numeric ---\n",
        "    if \"year\" in df.columns:\n",
        "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # --- 4. Assign generation manually (no merge, no year_start/year_end contamination) ---\n",
        "    df[\"gen\"] = pd.NA\n",
        "\n",
        "    for idx, row in gen_lookup.iterrows():\n",
        "        mask = (\n",
        "            (df[\"make\"] == row[\"make\"]) &\n",
        "            (df[\"model\"] == row[\"model\"]) &\n",
        "            (df[\"year\"].between(row[\"year_start\"], row[\"year_end\"], inclusive=\"both\"))\n",
        "        )\n",
        "        df.loc[mask, \"gen\"] = row[\"gen\"]\n",
        "\n",
        "    df[\"gen\"] = df[\"gen\"].astype(\"Int64\")\n",
        "\n",
        "    # --- 5. Create model_gen ---\n",
        "    df[\"model_gen\"] = df.apply(\n",
        "        lambda r: f\"{r['model']}_{r['gen']}\" if pd.notna(r[\"gen\"]) else None,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return df"
      ],
      "id": "6f818106",
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}