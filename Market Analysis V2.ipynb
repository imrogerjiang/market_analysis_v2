{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ae2ea91a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2ea91a",
        "outputId": "8fcce385-2a77-4e2c-f402-fc0d654ea4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import Dict, Optional, List\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "sys.path.append('/content/drive/Shareddrives/market_analysis_v2/scripts')\n",
        "from clean_cs import *\n",
        "from clean_fb import *\n",
        "from constants_and_helpers import *\n",
        "from enrich import*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_lookup = pd.read_csv(\"/content/drive/Shareddrives/market_analysis_v2/gen_lookup.csv\")\n",
        "listings = pd.read_csv(\"/content/drive/Shareddrives/market_analysis_v2/listings.csv\")"
      ],
      "metadata": {
        "id": "J37vmfyrnkAQ"
      },
      "id": "J37vmfyrnkAQ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constants_and_helpers.py\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "# ---------- Constants for CS (Carsales/General Scrapes) ----------\n",
        "YEAR_MIN, YEAR_MAX = 1980, 2035\n",
        "ORDER: List[str] = ['href', 'year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']\n",
        "\n",
        "YEAR_RE  = r'\\b(19[89]\\d|20[0-3]\\d)\\b'\n",
        "PRICE_RE = r'^\\s*\\$\\s*[\\d,]+(?:\\.\\d{2})?\\b'\n",
        "ODOM_RE  = r'^\\s*\\d{1,3}(?:,\\d{3})+\\s*km\\s*$'\n",
        "URL_RE   = r'^(?:https?://|www\\.)'\n",
        "TX, SELLER = {'automatic', 'manual'}, {'private', 'dealer used'}\n",
        "\n",
        "THRESH: Dict[str, float] = {\n",
        "    'year_make_model': 0.50,\n",
        "    \"listed_price\":           0.60,\n",
        "    'transmission':    0.80,\n",
        "    'odometer':        0.60,\n",
        "    'seller_type':     0.70,\n",
        "}\n",
        "\n",
        "# ---------- Constants for FB (Facebook Marketplace Scrapes) ----------\n",
        "FB_ORDER: List[str] = ['href', 'year_make_model', 'listed_price', 'odometer', 'location']\n",
        "# THRESH_FB values are used for identifying FB specific columns.\n",
        "# 'href' and 'year_make_model' are critical for data structuring.\n",
        "# 'listed_price' and 'odometer' are numeric and generally have clear patterns.\n",
        "# 'location' is the hardest to identify solely by content, so it has a lower threshold\n",
        "# and is often inferred from remaining columns or specific column names like 'c'.\n",
        "THRESH_FB: Dict[str, float] = {\n",
        "    'href':            0.80,\n",
        "    'year_make_model': 0.50,\n",
        "    'listed_price':    0.60,\n",
        "    'odometer':        0.60,\n",
        "    'location':        0.40,\n",
        "}\n",
        "\n",
        "# ---------- Predicates ----------\n",
        "def _ratio(mask: pd.Series) -> float:\n",
        "    return float(mask.mean()) if len(mask) else 0.0\n",
        "\n",
        "def _yr_ok(s: pd.Series) -> pd.Series:\n",
        "    years = pd.to_numeric(s.astype(str).str.extract(YEAR_RE, expand=False), errors='coerce')\n",
        "    return years.between(YEAR_MIN, YEAR_MAX)\n",
        "\n",
        "PRED = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    \"listed_price\":           lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'transmission':    lambda s: s.astype(str).str.strip().str.lower().isin(TX),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "    'seller_type':     lambda s: s.astype(str).str.strip().str.lower().isin(SELLER),\n",
        "}\n",
        "\n",
        "PRED_FB = {\n",
        "    'href':            lambda s: s.astype(str).str.contains(URL_RE, case=False, na=False),\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    'listed_price':    lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "}\n",
        "\n",
        "# ---------- Core Identification Functions ----------\n",
        "def identify_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical Carsales/General column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in ORDER}\n",
        "\n",
        "    href_col = cols[0]\n",
        "\n",
        "    # exclude URL-like columns from other detection\n",
        "    url_ratio = {c: _ratio(df[c].astype(str).str.contains(URL_RE, case=False, na=False)) for c in cols}\n",
        "    urlish = {c for c, r in url_ratio.items() if r >= 0.50}\n",
        "    blocked = {href_col} | urlish\n",
        "\n",
        "    remaining = [c for c in cols if c not in blocked]\n",
        "    picks = {t: None for t in PRED}\n",
        "\n",
        "    for t in PRED:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED[t](df[c])) for c in remaining}\n",
        "        best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "        if best_score >= THRESH[t]:\n",
        "            picks[t] = best_col\n",
        "            remaining.remove(best_col)\n",
        "\n",
        "    trim_col = None\n",
        "    ymm = picks.get('year_make_model')\n",
        "    if ymm in cols:\n",
        "        i = cols.index(ymm)\n",
        "        if i + 1 < len(cols):\n",
        "            trim_col = cols[i + 1]\n",
        "\n",
        "    return {'href': href_col, **picks, 'trim': trim_col}\n",
        "\n",
        "def identify_fb_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical Facebook Marketplace column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in FB_ORDER}\n",
        "\n",
        "    picks = {t: None for t in FB_ORDER}\n",
        "    remaining = set(cols)\n",
        "\n",
        "    # Prioritize 'href'\n",
        "    href_scores = {c: _ratio(PRED_FB['href'](df[c])) for c in remaining}\n",
        "    best_href_col, best_href_score = None, 0.0\n",
        "    if href_scores:\n",
        "        best_href_col, best_href_score = max(href_scores.items(), key=lambda kv: kv[1])\n",
        "\n",
        "    if best_href_score >= THRESH_FB['href']:\n",
        "        picks['href'] = best_href_col\n",
        "        remaining.remove(best_href_col)\n",
        "    elif 'x1i10hfl href' in remaining and _ratio(PRED_FB['href'](df['x1i10hfl href'])) >= THRESH_FB['href']:\n",
        "        # Fallback to specific column name if it exists and matches pattern well\n",
        "        picks['href'] = 'x1i10hfl href'\n",
        "        remaining.remove('x1i10hfl href')\n",
        "\n",
        "\n",
        "    # Identify 'year_make_model', 'listed_price', 'odometer'\n",
        "    for t in ['year_make_model', 'listed_price', 'odometer']:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED_FB[t](df[c])) for c in remaining}\n",
        "        if scores:\n",
        "            best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "            if best_score >= THRESH_FB[t]:\n",
        "                picks[t] = best_col\n",
        "                remaining.remove(best_col)\n",
        "\n",
        "    # Assign 'location'\n",
        "    if picks['location'] is None:\n",
        "        if 'c' in remaining: # The common FB Marketplace location column name\n",
        "            picks['location'] = 'c'\n",
        "            remaining.remove('c')\n",
        "        elif len(remaining) == 1: # If only one column left, it's likely location\n",
        "            picks['location'] = remaining.pop()\n",
        "\n",
        "    return picks"
      ],
      "metadata": {
        "id": "gECV1vdedUm0"
      },
      "id": "gECV1vdedUm0",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean_fb.py\n",
        "\n",
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "# Import constants and helper functions from constants_and_helpers.py\n",
        "# from constants_and_helpers import identify_fb_columns\n",
        "\n",
        "def clean_fb(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Detect, rename, clean numeric/text data, and return standardized columns for Facebook Marketplace.\"\"\"\n",
        "    mapping = identify_fb_columns(df)\n",
        "    out = pd.DataFrame() # Initialize an empty DataFrame to store cleaned data\n",
        "\n",
        "    # Map columns based on identified mapping\n",
        "    # Only create columns in 'out' if they were successfully mapped and exist in original df\n",
        "    for canonical_col, src_col in mapping.items():\n",
        "        if src_col is not None and src_col in df.columns:\n",
        "            out[canonical_col] = df[src_col]\n",
        "\n",
        "    # Split the year_make_model column into 'year', 'make', 'model'\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_df = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        # Assign split parts to new columns, handling cases where parts might be missing\n",
        "        out['year'] = split_df[0] if 0 in split_df.columns else pd.NA\n",
        "        out['make'] = split_df[1] if 1 in split_df.columns else pd.NA\n",
        "        out['model'] = split_df[2] if 2 in split_df.columns else pd.NA\n",
        "    else:\n",
        "        # If 'year_make_model' was not found, initialize year/make/model to NA\n",
        "        out[['year', 'make', 'model']] = pd.NA\n",
        "\n",
        "    # Clean hrefs (remove query strings)\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    # Clean numeric columns: listed_price, odometer\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            # Handle 'Free' for listed_price specifically before conversion\n",
        "            if col == 'listed_price':\n",
        "                out = out[out[col].astype(str).str.lower() != \"free\"]\n",
        "\n",
        "            out[col] = (\n",
        "                out[col].astype(str)\n",
        "                .replace(r'[^\\d]', '', regex=True) # Remove non-digit characters\n",
        "                .replace('', pd.NA) # Replace empty strings with NA\n",
        "                .astype(float) # Convert to float first to handle NA\n",
        "                .astype('Int64') # Convert to nullable integer type\n",
        "            )\n",
        "\n",
        "    # Removing listings with null values for essential columns\n",
        "    cols_to_check_for_na = []\n",
        "    if 'listed_price' in out.columns: cols_to_check_for_na.append('listed_price')\n",
        "    if 'odometer' in out.columns: cols_to_check_for_na.append('odometer')\n",
        "    if 'year' in out.columns: cols_to_check_for_na.append('year')\n",
        "\n",
        "    if cols_to_check_for_na:\n",
        "        out = out.dropna(subset=cols_to_check_for_na)\n",
        "\n",
        "    # Remove crashed listings (magic numbers, ideally these would be parameters)\n",
        "    if 'listed_price' in out.columns:\n",
        "        out = out[out[\"listed_price\"] != 1234]\n",
        "        out = out[out[\"listed_price\"] != 12345]\n",
        "\n",
        "    # Select only the required columns in order\n",
        "    final_columns = ['href', 'year', 'make', 'model', \"listed_price\", 'odometer', 'location']\n",
        "    return out[[c for c in final_columns if c in out.columns]]"
      ],
      "metadata": {
        "id": "Fd5YIZxjdXVP"
      },
      "id": "Fd5YIZxjdXVP",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "# Import constants and helper functions from constants_and_helpers.py\n",
        "# from constants_and_helpers import identify_columns\n",
        "\n",
        "def clean_cs(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Detect, rename, clean numeric/text data, and return standardized columns for Carsales/General Scrapes.\n",
        "    Also, saves the raw input DataFrame to a uniquely timestamped CSV file and adds the filename as a 'raw' column.\n",
        "    \"\"\"\n",
        "    # Define the directory for raw data and create it if it doesn't exist\n",
        "    raw_data_dir = 'data/raws'\n",
        "    os.makedirs(raw_data_dir, exist_ok=True)\n",
        "\n",
        "    # Generate a unique timestamped filename for the raw data\n",
        "    timestamp = datetime.now()\n",
        "    raw_filename = ''\n",
        "    while True:\n",
        "        raw_filename = os.path.join(raw_data_dir, f\"raw_carsales_data_{timestamp.strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "        if not os.path.exists(raw_filename):\n",
        "            break\n",
        "        timestamp += timedelta(seconds=1) # Increment by one second if file exists\n",
        "\n",
        "    # Save the raw input DataFrame\n",
        "    df.to_csv(raw_filename, index=False)\n",
        "\n",
        "    mapping = identify_columns(df)\n",
        "    out = pd.DataFrame()\n",
        "\n",
        "    # Map columns\n",
        "    if mapping['href'] is not None:\n",
        "        out['href'] = df[mapping['href']]\n",
        "    for col in ['year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']:\n",
        "        src = mapping.get(col)\n",
        "        if src is not None:\n",
        "            out[col] = df[src]\n",
        "\n",
        "    # Add the raw filename to the output DataFrame\n",
        "    out['raw'] = os.path.basename(raw_filename)\n",
        "\n",
        "    # Split \"year make model\"\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_cols = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        # Ensure the split_cols DataFrame has at least 3 columns before assigning\n",
        "        out['year'] = split_cols[0] if 0 in split_cols.columns else pd.NA\n",
        "        out['make'] = split_cols[1] if 1 in split_cols.columns else pd.NA\n",
        "        out['model'] = split_cols[2] if 2 in split_cols.columns else pd.NA\n",
        "    else:\n",
        "        out[['year', 'make', 'model']] = pd.NA\n",
        "\n",
        "    # Clean hrefs (remove query strings)\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    # Clean numeric columns\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            out[col] = (\n",
        "                out[col].astype(str)\n",
        "                .replace(r'[^ا-ي٠-٩ #%&,-.0-9:<=>£°€️\\d]', '', regex=True)\n",
        "                .replace('', pd.NA)\n",
        "                .astype(float)\n",
        "                .astype('Int64')\n",
        "            )\n",
        "\n",
        "    # Convert odometer to thousands of km\n",
        "    if 'odometer' in out.columns:\n",
        "        out['odometer'] = out['odometer'] // 1000\n",
        "\n",
        "    # Build final tidy table\n",
        "    final_cols = ['raw', 'href', 'year', 'make', 'model', \"listed_price\", 'trim', 'odometer', 'seller_type']\n",
        "    return out[[c for c in final_cols if c in out.columns]]\n"
      ],
      "metadata": {
        "id": "jOULGvg0demy"
      },
      "id": "jOULGvg0demy",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24ad46d3"
      },
      "source": [
        "# Task\n",
        "`save_raw_df` function will be implemented, followed by updates to `clean_cs` and `clean_fb` to integrate it. Finally, both cleaning functions will be tested to verify the conditional raw data saving and 'raw' column inclusion based on the `save_raw` parameter."
      ],
      "id": "24ad46d3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e16e6fa8"
      },
      "source": [
        "## Define/Update `save_raw_df` in `constants_and_helpers` cell\n",
        "\n",
        "### Subtask:\n",
        "Provide the complete updated code for the `constants_and_helpers` cell (`gECV1vdedUm0`), ensuring it includes the definition of the `save_raw_df` function. This helper function will handle creating the `data/raws` directory, generating a unique timestamped filename (incrementing seconds if needed), saving the input DataFrame, and returning a copy of the DataFrame with an added 'raw' column. It will accept the raw DataFrame and a `source` identifier (e.g., 'cs', 'fb') as arguments. This will overwrite the existing content of the cell.\n"
      ],
      "id": "e16e6fa8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8dd36bb"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining the `save_raw_df` function and integrating it into the `constants_and_helpers` cell, ensuring all existing code, imports, and constants are retained. I will generate the complete updated code for the cell, including the new function and necessary imports, to fulfill this requirement.\n",
        "\n"
      ],
      "id": "c8dd36bb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edf5cf70"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ---------- Constants for CS (Carsales/General Scrapes) ----------\n",
        "YEAR_MIN, YEAR_MAX = 1980, 2035\n",
        "ORDER: List[str] = ['href', 'year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']\n",
        "\n",
        "YEAR_RE  = r'\\b(19[89]\\d|20[0-3]\\d)\\b'\n",
        "PRICE_RE = r'^\\s*\\$\\s*[\\d,]+(?:\\.\\d{2})?\\b'\n",
        "ODOM_RE  = r'^\\s*\\d{1,3}(?:,\\d{3})+\\s*km\\s*$'\n",
        "URL_RE   = r'^(?:https?://|www\\.)'\n",
        "TX, SELLER = {'automatic', 'manual'}, {'private', 'dealer used'}\n",
        "\n",
        "THRESH: Dict[str, float] = {\n",
        "    'year_make_model': 0.50,\n",
        "    \"listed_price\":           0.60,\n",
        "    'transmission':    0.80,\n",
        "    'odometer':        0.60,\n",
        "    'seller_type':     0.70,\n",
        "}\n",
        "\n",
        "# ---------- Constants for FB (Facebook Marketplace Scrapes) ----------\n",
        "FB_ORDER: List[str] = ['href', 'year_make_model', 'listed_price', 'odometer', 'location']\n",
        "# THRESH_FB values are used for identifying FB specific columns.\n",
        "# 'href' and 'year_make_model' are critical for data structuring.\n",
        "# 'listed_price' and 'odometer' are numeric and generally have clear patterns.\n",
        "# 'location' is the hardest to identify solely by content, so it has a lower threshold\n",
        "# and is often inferred from remaining columns or specific column names like 'c'.\n",
        "THRESH_FB: Dict[str, float] = {\n",
        "    'href':            0.80,\n",
        "    'year_make_model': 0.50,\n",
        "    'listed_price':    0.60,\n",
        "    'odometer':        0.60,\n",
        "    'location':        0.40,\n",
        "}\n",
        "\n",
        "# ---------- Predicates ----------\n",
        "def _ratio(mask: pd.Series) -> float:\n",
        "    return float(mask.mean()) if len(mask) else 0.0\n",
        "\n",
        "def _yr_ok(s: pd.Series) -> pd.Series:\n",
        "    years = pd.to_numeric(s.astype(str).str.extract(YEAR_RE, expand=False), errors='coerce')\n",
        "    return years.between(YEAR_MIN, YEAR_MAX)\n",
        "\n",
        "PRED = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    \"listed_price\":           lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'transmission':    lambda s: s.astype(str).str.strip().str.lower().isin(TX),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "    'seller_type':     lambda s: s.astype(str).str.strip().str.lower().isin(SELLER),\n",
        "}\n",
        "\n",
        "PRED_FB = {\n",
        "    'href':            lambda s: s.astype(str).str.contains(URL_RE, case=False, na=False),\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    'listed_price':    lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "}\n",
        "\n",
        "# ---------- Core Identification Functions ----------\n",
        "def identify_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical Carsales/General column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in ORDER}\n",
        "\n",
        "    href_col = cols[0]\n",
        "\n",
        "    # exclude URL-like columns from other detection\n",
        "    url_ratio = {c: _ratio(df[c].astype(str).str.contains(URL_RE, case=False, na=False)) for c in cols}\n",
        "    urlish = {c for c, r in url_ratio.items() if r >= 0.50}\n",
        "    blocked = {href_col} | urlish\n",
        "\n",
        "    remaining = [c for c in cols if c not in blocked]\n",
        "    picks = {t: None for t in PRED}\n",
        "\n",
        "    for t in PRED:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED[t](df[c])) for c in remaining}\n",
        "        best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "        if best_score >= THRESH[t]:\n",
        "            picks[t] = best_col\n",
        "            remaining.remove(best_col)\n",
        "\n",
        "    trim_col = None\n",
        "    ymm = picks.get('year_make_model')\n",
        "    if ymm in cols:\n",
        "        i = cols.index(ymm)\n",
        "        if i + 1 < len(cols):\n",
        "            trim_col = cols[i + 1]\n",
        "\n",
        "    return {'href': href_col, **picks, 'trim': trim_col}\n",
        "\n",
        "def identify_fb_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identify and map each canonical Facebook Marketplace column.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in FB_ORDER}\n",
        "\n",
        "    picks = {t: None for t in FB_ORDER}\n",
        "    remaining = set(cols)\n",
        "\n",
        "    # Prioritize 'href'\n",
        "    href_scores = {c: _ratio(PRED_FB['href'](df[c])) for c in remaining}\n",
        "    best_href_col, best_href_score = None, 0.0\n",
        "    if href_scores:\n",
        "        best_href_col, best_href_score = max(href_scores.items(), key=lambda kv: kv[1])\n",
        "\n",
        "    if best_href_score >= THRESH_FB['href']:\n",
        "        picks['href'] = best_href_col\n",
        "        remaining.remove(best_href_col)\n",
        "    elif 'x1i10hfl href' in remaining and _ratio(PRED_FB['href'](df['x1i10hfl href'])) >= THRESH_FB['href']:\n",
        "        # Fallback to specific column name if it exists and matches pattern well\n",
        "        picks['href'] = 'x1i10hfl href'\n",
        "        remaining.remove('x1i10hfl href')\n",
        "\n",
        "\n",
        "    # Identify 'year_make_model', 'listed_price', 'odometer'\n",
        "    for t in ['year_make_model', 'listed_price', 'odometer']:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED_FB[t](df[c])) for c in remaining}\n",
        "        if scores:\n",
        "            best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "            if best_score >= THRESH_FB[t]:\n",
        "                picks[t] = best_col\n",
        "                remaining.remove(best_col)\n",
        "\n",
        "    # Assign 'location'\n",
        "    if picks['location'] is None:\n",
        "        if 'c' in remaining: # The common FB Marketplace location column name\n",
        "            picks['location'] = 'c'\n",
        "            remaining.remove('c')\n",
        "        elif len(remaining) == 1: # If only one column left, it's likely location\n",
        "            picks['location'] = remaining.pop()\n",
        "\n",
        "    return picks\n",
        "\n",
        "def save_raw_df(df: pd.DataFrame, source: str) -> pd.DataFrame:\n",
        "    \"\"\"Saves the raw DataFrame to a uniquely timestamped CSV file and adds the filename as a 'raw' column.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame to be saved.\n",
        "        source (str): A string identifier for the data source (e.g., 'cs', 'fb').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A copy of the input DataFrame with a 'raw' column added, containing the base filename.\n",
        "    \"\"\"\n",
        "    raw_data_dir = 'data/raws'\n",
        "    os.makedirs(raw_data_dir, exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.now()\n",
        "    raw_filename = ''\n",
        "    while True:\n",
        "        raw_filename = os.path.join(raw_data_dir, f\"raw_{source}_data_{timestamp.strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "        if not os.path.exists(raw_filename):\n",
        "            break\n",
        "        timestamp += timedelta(seconds=1)\n",
        "\n",
        "    df.to_csv(raw_filename, index=False)\n",
        "\n",
        "    df_copy = df.copy()\n",
        "    df_copy['raw'] = os.path.basename(raw_filename)\n",
        "\n",
        "    return df_copy"
      ],
      "id": "edf5cf70",
      "execution_count": 115,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}