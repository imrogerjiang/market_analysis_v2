{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ae2ea91a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2ea91a",
        "outputId": "3cc86bdf-02b2-4005-bdbb-d38e9e18e530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import Dict, Optional, List\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "sys.path.append('/content/drive/Shareddrives/market_analysis_v2/scripts')\n",
        "# from clean_cs import *\n",
        "# from clean_fb import *\n",
        "# from constants_and_helpers import *\n",
        "from enrich import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scripts"
      ],
      "metadata": {
        "id": "1DYdMWKeEnLW"
      },
      "id": "1DYdMWKeEnLW"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "# --- Carsales/General Scrapes (CS) Constants ---\n",
        "YEAR_MIN, YEAR_MAX = 1980, 2035\n",
        "ORDER: List[str] = ['href', 'year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']\n",
        "\n",
        "YEAR_RE  = r'\\b(19[89]\\d|20[0-3]\\d)\\b'\n",
        "PRICE_RE = r'^(?:AU\\$|\\$)\\s*[\\d,]+(?:\\.\\d{2})?\\b' # Made currency symbol mandatory\n",
        "ODOM_RE  = r'^\\s*\\d+(?:,?\\d{3})*\\s*km\\s*$' # Made 'km' suffix mandatory\n",
        "URL_RE   = r'^(?:https?://|www\\.)'\n",
        "TX, SELLER = {'automatic', 'manual'}, {'private', 'dealer used'}\n",
        "\n",
        "THRESH: Dict[str, float] = {\n",
        "    'year_make_model': 0.50,\n",
        "    \"listed_price\":           0.60,\n",
        "    'transmission':    0.80,\n",
        "    'odometer':        0.60,\n",
        "    'seller_type':     0.70,\n",
        "}\n",
        "\n",
        "# --- Facebook Marketplace (FB) Constants ---\n",
        "FB_ORDER: List[str] = ['href', 'year_make_model', 'listed_price', 'odometer', 'location']\n",
        "THRESH_FB: Dict[str, float] = {\n",
        "    'href':            0.80,\n",
        "    'year_make_model': 0.50,\n",
        "    'listed_price':    0.60,\n",
        "    'odometer':        0.60,\n",
        "    'location':        0.40,\n",
        "}\n",
        "\n",
        "# --- Predicates (Validation Rules) ---\n",
        "def _ratio(mask: pd.Series) -> float:\n",
        "    return float(mask.mean()) if len(mask) else 0.0\n",
        "\n",
        "def _yr_ok(s: pd.Series) -> pd.Series:\n",
        "    years = pd.to_numeric(s.astype(str).str.extract(YEAR_RE, expand=False), errors='coerce')\n",
        "    return years.between(YEAR_MIN, YEAR_MAX)\n",
        "\n",
        "PRED = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    \"listed_price\":           lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'transmission':    lambda s: s.astype(str).str.strip().str.lower().isin(TX),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "    'seller_type':     lambda s: s.astype(str).str.strip().str.lower().isin(SELLER),\n",
        "}\n",
        "\n",
        "PRED_FB = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    'listed_price':    lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "}\n",
        "\n",
        "# --- Core Identification Functions ---\n",
        "def identify_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identifies and maps raw DataFrame columns to canonical Carsales/General columns.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in ORDER}\n",
        "\n",
        "    href_col = cols[0]\n",
        "\n",
        "    # Exclude URL-like columns from other detection logic\n",
        "    url_ratio = {c: _ratio(df[c].astype(str).str.contains(URL_RE, case=False, na=False)) for c in cols}\n",
        "    urlish = {c for c, r in url_ratio.items() if r >= 0.50}\n",
        "    blocked = {href_col} | urlish\n",
        "\n",
        "    remaining = [c for c in cols if c not in blocked]\n",
        "    picks = {t: None for t in PRED}\n",
        "\n",
        "    for t in PRED:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED[t](df[c])) for c in remaining}\n",
        "        best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "        if best_score >= THRESH[t]:\n",
        "            picks[t] = best_col\n",
        "            remaining.remove(best_col)\n",
        "\n",
        "    trim_col = None\n",
        "    ymm = picks.get('year_make_model')\n",
        "    if ymm in cols:\n",
        "        i = cols.index(ymm)\n",
        "        if i + 1 < len(cols):\n",
        "            trim_col = cols[i + 1]\n",
        "\n",
        "    return {'href': href_col, **picks, 'trim': trim_col}\n",
        "\n",
        "def identify_fb_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identifies and maps raw DataFrame columns to canonical Facebook Marketplace columns.\n",
        "    Note: 'href' is assumed to be the first column and is handled by clean_fb directly.\n",
        "    \"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in FB_ORDER}\n",
        "\n",
        "    picks = {t: None for t in FB_ORDER}\n",
        "    remaining = set(cols)\n",
        "\n",
        "    # 'href' is now handled externally by clean_fb and is assumed to be the first column\n",
        "    # So we set it to None here or simply don't try to identify it.\n",
        "    # We explicitly remove the first column from 'remaining' as it's the href\n",
        "    if cols and cols[0] in remaining:\n",
        "        remaining.remove(cols[0])\n",
        "    picks['href'] = None # No longer identified by this function\n",
        "\n",
        "    # Identify 'year_make_model', 'listed_price', 'odometer'\n",
        "    for t in ['year_make_model', 'listed_price', 'odometer']:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED_FB[t](df[c])) for c in remaining}\n",
        "        if scores:\n",
        "            best_col, score = max(scores.items(), key=lambda kv: kv[1])\n",
        "            if score >= THRESH_FB[t]:\n",
        "                picks[t] = best_col\n",
        "                remaining.remove(best_col)\n",
        "\n",
        "    # Assign 'location', often found in column 'c' or as the last remaining column\n",
        "    if picks['location'] is None:\n",
        "        if 'c' in remaining:\n",
        "            picks['location'] = 'c'\n",
        "            remaining.remove('c')\n",
        "        elif len(remaining) == 1:\n",
        "            picks['location'] = remaining.pop()\n",
        "\n",
        "    return picks"
      ],
      "metadata": {
        "id": "gECV1vdedUm0"
      },
      "id": "gECV1vdedUm0",
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa5c70d3"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "def clean_cs(df: pd.DataFrame, save_raw: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Business Logic for clean_cs function:\n",
        "\n",
        "    This function processes raw DataFrame outputs from Carsales/General web scrapes to standardize\n",
        "    and clean vehicle listing data into a consistent format for analysis.\n",
        "\n",
        "    Key steps and business rules:\n",
        "    1.  **Raw Data Preservation (Optional):** If `save_raw` is True, the original DataFrame\n",
        "        is saved to a timestamped CSV, and a 'raw' column (filename) is added to the output.\n",
        "    2.  **Column Identification:** Dynamically maps raw DataFrame columns to canonical names\n",
        "        ('href', 'year_make_model', 'listed_price', 'odometer', etc.) using `identify_columns`.\n",
        "    3.  **Data Extraction & Standardization:**\n",
        "        *   Cleans 'href' by removing query parameters.\n",
        "        *   Splits 'year_make_model' into 'year', 'make', and 'model'; converts 'year' to integer.\n",
        "        *   Converts 'listed_price' and 'odometer' to integer, removing non-numeric characters.\n",
        "        *   Transforms 'odometer' values from 'km' to '000 km' (e.g., 180,000 km -> 180).\n",
        "    4.  **Output Structure:** Returns a DataFrame with a standardized set of columns for consistency.\n",
        "    \"\"\"\n",
        "    raw_col_value = None\n",
        "    if save_raw:\n",
        "        raw_data_dir = 'data/raws'\n",
        "        os.makedirs(raw_data_dir, exist_ok=True)\n",
        "        timestamp = datetime.now()\n",
        "        raw_filename = ''\n",
        "        while True:\n",
        "            raw_filename = os.path.join(raw_data_dir, f\"raw_carsales_data_{timestamp.strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "            if not os.path.exists(raw_filename):\n",
        "                break\n",
        "            timestamp += timedelta(seconds=1)\n",
        "        df.to_csv(raw_filename, index=False)\n",
        "        raw_col_value = os.path.basename(raw_filename)\n",
        "\n",
        "    if 'identify_columns' not in globals():\n",
        "        raise NameError(\"Function 'identify_columns' not found. Please ensure 'constants_and_helpers.py' or cell 'gECV1vdedUm0' has been executed.\")\n",
        "\n",
        "    # Always use the first column for 'href'\n",
        "    out = pd.DataFrame()\n",
        "    if not df.empty and len(df.columns) > 0:\n",
        "        out['href'] = df.iloc[:, 0]\n",
        "\n",
        "    # Use original identify_columns for other fields if needed, or update this logic if all should be positional\n",
        "    mapping = identify_columns(df)\n",
        "    # Only apply mapping for columns other than href, as href is now fixed\n",
        "    for col in ['year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']:\n",
        "        src = mapping.get(col)\n",
        "        if src is not None and src != out['href'].name: # Ensure we don't re-add the href column\n",
        "            out[col] = df[src]\n",
        "\n",
        "    if save_raw and raw_col_value:\n",
        "        out['raw'] = raw_col_value\n",
        "\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_cols = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        if 0 in split_cols.columns:\n",
        "            out['year'] = pd.to_numeric(\n",
        "                split_cols[0].astype(str).str.replace(r'[^\\d]', '', regex=True),\n",
        "                errors='coerce'\n",
        "            ).astype('Int64')\n",
        "        else:\n",
        "            out['year'] = pd.NA\n",
        "        out['make'] = split_cols[1] if 1 in split_cols.columns else pd.NA\n",
        "        out['model'] = split_cols[2] if 2 in split_cols.columns else pd.NA\n",
        "    else:\n",
        "        out[['year', 'make', 'model']] = pd.NA\n",
        "\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            out[col] = pd.to_numeric(\n",
        "                out[col].astype(str).str.replace(r'[^\\d]', '', regex=True),\n",
        "                errors='coerce'\n",
        "            ).astype('Int64')\n",
        "\n",
        "    if 'odometer' in out.columns:\n",
        "        out['odometer'] = out['odometer'] // 1000\n",
        "\n",
        "    final_cols = ['href', 'year', 'make', 'model', \"listed_price\", 'trim', 'odometer', 'seller_type']\n",
        "    if save_raw:\n",
        "        final_cols.insert(0, 'raw')\n",
        "    return out[[c for c in final_cols if c in out.columns]]"
      ],
      "execution_count": 107,
      "outputs": [],
      "id": "aa5c70d3"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_fb(df: pd.DataFrame, save_raw: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Business Logic for clean_fb function:\n",
        "\n",
        "    This function processes raw DataFrame outputs from Facebook Marketplace scrapes to standardize\n",
        "    and clean vehicle listing data into a consistent format for analysis.\n",
        "\n",
        "    Key steps and business rules:\n",
        "    1.  **Raw Data Preservation (Optional):** If `save_raw` is True, the original DataFrame\n",
        "        is saved to a timestamped CSV, and a 'raw' column (filename) is added to the output.\n",
        "    2.  **Column Identification:** Dynamically maps raw DataFrame columns to canonical names\n",
        "        ('href', 'year_make_model', 'listed_price', 'odometer', 'location') using `identify_fb_columns`.\n",
        "    3.  **Data Extraction & Standardization:**\n",
        "        *   Cleans 'href' by removing query parameters.\n",
        "        *   Splits 'year_make_model' into 'year', 'make', and 'model'; converts 'year' to integer.\n",
        "        *   Converts 'listed_price' and 'odometer' to integer, removing non-numeric characters.\n",
        "        *   Filters out listings with 'listed_price' explicitly marked as \"free\".\n",
        "    4.  **Data Quality Filtering:** Drops rows with missing (`pd.NA`) values in critical columns\n",
        "        ('listed_price', 'odometer', 'year') to ensure data integrity. Also removes listings\n",
        "        with a placeholder 'listed_price' of 12345.\n",
        "    5.  **Output Structure:** Returns a DataFrame with a standardized set of columns for consistency.\n",
        "    \"\"\"\n",
        "    raw_col_value = None\n",
        "    if save_raw:\n",
        "        raw_data_dir = 'data/raws'\n",
        "        os.makedirs(raw_data_dir, exist_ok=True)\n",
        "        timestamp = datetime.now()\n",
        "        raw_filename = ''\n",
        "        while True:\n",
        "            raw_filename = os.path.join(raw_data_dir, f\"raw_facebook_data_{timestamp.strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "            if not os.path.exists(raw_filename):\n",
        "                break\n",
        "            timestamp += timedelta(seconds=1)\n",
        "        df.to_csv(raw_filename, index=False)\n",
        "        raw_col_value = os.path.basename(raw_filename)\n",
        "\n",
        "    if 'identify_fb_columns' not in globals():\n",
        "        raise NameError(\"Function 'identify_fb_columns' not found. Please ensure 'constants_and_helpers.py' or cell 'gECV1vdedUm0' has been executed.\")\n",
        "\n",
        "    out = pd.DataFrame()\n",
        "    # Always use the first column for 'href'\n",
        "    if not df.empty and len(df.columns) > 0:\n",
        "        out['href'] = df.iloc[:, 0]\n",
        "\n",
        "    mapping = identify_fb_columns(df)\n",
        "    # Only apply mapping for columns other than href, as href is now fixed\n",
        "    for canonical_col, src_col in mapping.items():\n",
        "        if canonical_col != 'href' and src_col is not None and src_col in df.columns:\n",
        "            out[canonical_col] = df[src_col]\n",
        "\n",
        "    if save_raw and raw_col_value:\n",
        "        out['raw'] = raw_col_value\n",
        "\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_df = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        if 0 in split_df.columns:\n",
        "            out['year'] = split_df[0].astype(str).str.replace(r'[^\\d]', '', regex=True).replace('', pd.NA).astype(float).astype('Int64')\n",
        "        else:\n",
        "            out['year'] = pd.NA\n",
        "        out['make'] = split_df[1] if 1 in split_df.columns else pd.NA\n",
        "        out['model'] = split_df[2] if 2 in split_df.columns else pd.NA\n",
        "    else:\n",
        "        out[['year', 'make', 'model']] = pd.NA\n",
        "\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            if col == 'listed_price':\n",
        "                out = out[out[col].astype(str).str.lower() != \"free\"]\n",
        "            out[col] = pd.to_numeric(\n",
        "                out[col].astype(str).str.replace(r'[^\\d]', '', regex=True),\n",
        "                errors='coerce'\n",
        "            ).astype('Int64')\n",
        "\n",
        "    cols_to_check_for_na = []\n",
        "    if 'listed_price' in out.columns: cols_to_check_for_na.append('listed_price')\n",
        "    if 'odometer' in out.columns: cols_to_check_for_na.append('odometer')\n",
        "    if 'year' in out.columns: cols_to_check_for_na.append('year')\n",
        "\n",
        "    if cols_to_check_for_na:\n",
        "        out = out.dropna(subset=cols_to_check_for_na)\n",
        "\n",
        "    if 'listed_price' in out.columns:\n",
        "        out = out[out[\"listed_price\"] != 12345]\n",
        "        out = out[out[\"listed_price\"] > 3000]\n",
        "\n",
        "    final_columns = ['href', 'year', 'make', 'model', \"listed_price\", 'odometer', 'location']\n",
        "    if save_raw:\n",
        "        final_columns.insert(0, 'raw')\n",
        "    return out[[c for c in final_columns if c in out.columns]]"
      ],
      "metadata": {
        "id": "N5MMcCRVEbDl"
      },
      "id": "N5MMcCRVEbDl",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "def enrich_df(df: pd.DataFrame, gen_lookup: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Final clean after clean_cs or clean_fb, including generation assignment.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame to enrich.\n",
        "        gen_lookup (pd.DataFrame): A lookup table for car generations.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The enriched DataFrame.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Add date_scraped ---\n",
        "    df[\"date_scraped\"] = pd.Timestamp.now().normalize()\n",
        "\n",
        "    # --- 2. Normalise make & model ---\n",
        "    for col in [\"make\", \"model\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = (\n",
        "                df[col]\n",
        "                .astype(str)\n",
        "                .str.lower()\n",
        "                .str.replace(r\"[^a-z0-9]+\", \"\", regex=True)\n",
        "            )\n",
        "\n",
        "    # --- 3. Ensure year is numeric ---\n",
        "    if \"year\" in df.columns:\n",
        "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # --- 4. Assign generation manually (no merge, no year_start/year_end contamination) ---\n",
        "    df[\"gen\"] = pd.NA\n",
        "\n",
        "    for idx, row in gen_lookup.iterrows():\n",
        "        mask = (\n",
        "            (df[\"make\"] == row[\"make\"]) &\n",
        "            (df[\"model\"] == row[\"model\"]) &\n",
        "            (df[\"year\"].between(row[\"year_start\"], row[\"year_end\"], inclusive=\"both\"))\n",
        "        )\n",
        "        df.loc[mask, \"gen\"] = row[\"gen\"]\n",
        "\n",
        "    df[\"gen\"] = df[\"gen\"].astype(\"Int64\")\n",
        "\n",
        "    # --- 5. Create model_gen ---\n",
        "    df[\"model_gen\"] = df.apply(\n",
        "        lambda r: f\"{r['model']}_{r['gen']}\" if pd.notna(r[\"gen\"]) else None,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "9EoYNNjuIakO"
      },
      "id": "9EoYNNjuIakO",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_new_listings(listings: pd.DataFrame, gen_lookup: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Processes new listing files, cleans, enriches, and compares them against existing listings.\n",
        "\n",
        "    Args:\n",
        "        listings (pd.DataFrame): Existing DataFrame of car listings.\n",
        "        gen_lookup (pd.DataFrame): Lookup table for car generations.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, int, int, int, int]: A tuple containing:\n",
        "            - enriched_new_listings (pd.DataFrame): DataFrame of newly processed and enriched listings.\n",
        "            - tot_new (int): Total count of truly new listings.\n",
        "            - tot_updated (int): Total count of updated listings.\n",
        "            - tot_unchanged (int): Total count of unchanged listings.\n",
        "            - tot_tot (int): Total count of all listings processed from new files.\n",
        "    \"\"\"\n",
        "    tot_new, tot_updated, tot_unchanged, tot_tot = 0, 0, 0, 0\n",
        "    enriched_new_listings = pd.DataFrame()\n",
        "\n",
        "    # Dynamically find new CSV files\n",
        "    cs_files = glob.glob('/content/carsales*.csv')\n",
        "    fb_files = glob.glob('/content/facebook*.csv')\n",
        "\n",
        "    for file_path in cs_files + fb_files:\n",
        "        df_raw = pd.read_csv(file_path)\n",
        "        df_cleaned = None\n",
        "\n",
        "        if 'carsales' in os.path.basename(file_path):\n",
        "            df_cleaned = clean_cs(df_raw, save_raw=False)\n",
        "        elif 'facebook' in os.path.basename(file_path):\n",
        "            df_cleaned = clean_fb(df_raw, save_raw=False)\n",
        "        else:\n",
        "            print(f\"Unknown file type: {file_path}\")\n",
        "            continue\n",
        "\n",
        "        # Checking how many new, updated, unchanged listings\n",
        "        df_comparison = pd.merge(\n",
        "            df_cleaned,\n",
        "            listings,\n",
        "            on='href',\n",
        "            how='left',\n",
        "            suffixes=('_new', '_existing')\n",
        "        )\n",
        "\n",
        "        # Identify new listings\n",
        "        new_listings_df = df_comparison[df_comparison['listed_price_existing'].isnull()]\n",
        "        n_new = len(new_listings_df)\n",
        "\n",
        "        # Identify matched listings\n",
        "        matched_listings_df = df_comparison[df_comparison['listed_price_existing'].notnull()]\n",
        "\n",
        "        # From matched_listings, identify updated listings\n",
        "        updated_listings_df = matched_listings_df[\n",
        "            matched_listings_df['listed_price_new'] != matched_listings_df['listed_price_existing']\n",
        "        ]\n",
        "        n_updated = len(updated_listings_df)\n",
        "\n",
        "        # From matched_listings, identify unchanged listings\n",
        "        unchanged_listings_df = matched_listings_df[\n",
        "            matched_listings_df['listed_price_new'] == matched_listings_df['listed_price_existing']\n",
        "        ]\n",
        "        n_unchanged = len(unchanged_listings_df)\n",
        "\n",
        "        # Calculate total listings for the current file\n",
        "        n_total_listings = len(df_cleaned)\n",
        "\n",
        "        # Print the comparison result for the current file\n",
        "        print(f\"{file_path}    \\t {n_new=}   \\t {n_updated=} \\t {n_unchanged=} \\t Tot {n_total_listings}\")\n",
        "\n",
        "        tot_new += n_new\n",
        "        tot_updated += n_updated\n",
        "        tot_unchanged += n_unchanged\n",
        "        tot_tot += n_total_listings\n",
        "\n",
        "        if df_cleaned is not None:\n",
        "            df_enriched = enrich_df(df_cleaned, gen_lookup)\n",
        "            enriched_new_listings = pd.concat([enriched_new_listings, df_enriched], ignore_index=True)\n",
        "\n",
        "    print(f\"\\t \\t \\t \\t {tot_new=} \\t {tot_updated=}\\t {tot_unchanged=} {tot_tot=}\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "elwfHrt9xAZ9"
      },
      "id": "elwfHrt9xAZ9",
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23a71e21"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, Optional, List\n",
        "import glob # Import glob for file pattern matching\n",
        "\n",
        "def integrate_listings(listings_df: pd.DataFrame, gen_lookup: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Integrates new car listings from '/content/carsales*.csv' and '/content/facebook*.csv' files into an existing listings DataFrame.\n",
        "\n",
        "    Args:\n",
        "        listings_df (pd.DataFrame): The existing DataFrame of car listings.\n",
        "        gen_lookup (pd.DataFrame): The lookup table for car generations.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame (`listings_1`) with integrated, cleaned, and enriched listings,\n",
        "                      with existing listings handled by keeping the most recent entry.\n",
        "    \"\"\"\n",
        "    processed_dfs = []\n",
        "\n",
        "    # Dynamically find new CSV files\n",
        "    cs_files = glob.glob('/content/carsales*.csv')\n",
        "    fb_files = glob.glob('/content/facebook*.csv')\n",
        "    new_file_paths = cs_files + fb_files\n",
        "\n",
        "    for file_path in new_file_paths:\n",
        "        df_raw = pd.read_csv(file_path)\n",
        "        df_cleaned = None\n",
        "\n",
        "        if 'carsales' in os.path.basename(file_path):\n",
        "            df_cleaned = clean_cs(df_raw, save_raw=False)\n",
        "        elif 'facebook' in os.path.basename(file_path):\n",
        "            df_cleaned = clean_fb(df_raw, save_raw=False)\n",
        "        else:\n",
        "            print(f\"Unknown file type: {file_path}\")\n",
        "            continue\n",
        "\n",
        "        if df_cleaned is not None:\n",
        "            df_enriched = enrich_df(df_cleaned, gen_lookup)\n",
        "            processed_dfs.append(df_enriched)\n",
        "\n",
        "    if processed_dfs:\n",
        "        new_listings_df = pd.concat(processed_dfs, ignore_index=True)\n",
        "\n",
        "        # Define all possible columns that might exist in either DataFrame\n",
        "        # Get columns from existing listings and new listings, handling potential differences\n",
        "        all_cols = list(set(listings_df.columns) | set(new_listings_df.columns))\n",
        "\n",
        "        # Reindex both DataFrames to ensure they have the same columns\n",
        "        listings_aligned = listings_df.reindex(columns=all_cols, fill_value=pd.NA)\n",
        "        new_listings_aligned = new_listings_df.reindex(columns=all_cols, fill_value=pd.NA)\n",
        "\n",
        "        # Ensure 'date_scraped' is in datetime format for proper sorting\n",
        "        listings_aligned['date_scraped'] = pd.to_datetime(listings_aligned['date_scraped'], errors='coerce')\n",
        "        new_listings_aligned['date_scraped'] = pd.to_datetime(new_listings_aligned['date_scraped'], errors='coerce')\n",
        "\n",
        "        # Explicitly cast dtypes of new_listings_aligned to match listings_aligned for common columns\n",
        "        # This helps prevent FutureWarning and ensures consistent types across the concatenated DataFrame\n",
        "        for col in all_cols:\n",
        "            if col in listings_aligned.columns and col in new_listings_aligned.columns:\n",
        "                if listings_aligned[col].dtype != new_listings_aligned[col].dtype:\n",
        "                    try:\n",
        "                        if pd.api.types.is_numeric_dtype(listings_aligned[col]):\n",
        "                            if str(listings_aligned[col].dtype) == 'Int64':\n",
        "                                new_listings_aligned[col] = new_listings_aligned[col].astype('Int64')\n",
        "                            else:\n",
        "                                new_listings_aligned[col] = pd.to_numeric(new_listings_aligned[col], errors='coerce').astype(listings_aligned[col].dtype)\n",
        "                        else:\n",
        "                            new_listings_aligned[col] = new_listings_aligned[col].astype(listings_aligned[col].dtype)\n",
        "                    except (TypeError, ValueError):\n",
        "                        pass # Keep original dtype if casting causes error\n",
        "\n",
        "        # Concatenate the aligned Dataframes\n",
        "        listings_1 = pd.concat([listings_aligned, new_listings_aligned], ignore_index=True)\n",
        "    else:\n",
        "        listings_1 = listings_df.copy()\n",
        "\n",
        "    # Sort by href, then listed_price (lowest first), then date_scraped (most recent first), then drop duplicates keeping the first\n",
        "    listings_1 = listings_1.sort_values(by=['href', 'listed_price', 'date_scraped'], ascending=[True, True, False])\n",
        "    listings_1 = listings_1.drop_duplicates(subset=['href'], keep='first')\n",
        "\n",
        "    # Ensure 'gen' column is Int64 after all operations\n",
        "    listings_1['gen'] = listings_1['gen'].astype('Int64')\n",
        "\n",
        "    print(f\"Final listings_1 DataFrame has {len(listings_1)} unique listings after merging and de-duplication.\")\n",
        "    return listings_1"
      ],
      "id": "23a71e21",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "pYhOLy08cC6C"
      },
      "id": "pYhOLy08cC6C"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23f91c4e"
      },
      "source": [
        "def apply_regression(df: pd.DataFrame) -> (pd.DataFrame, pd.Series):\n",
        "    \"\"\"\n",
        "    Applies Huber regression to the input DataFrame to predict car prices.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing car listings.\n",
        "\n",
        "    Returns:\n",
        "        (pd.DataFrame, pd.Series): A tuple containing:\n",
        "            - The DataFrame with 'market_value' and 'value_diff' columns added.\n",
        "            - A Series of unscaled regression coefficients.\n",
        "    \"\"\"\n",
        "    listings_lr = df.copy()\n",
        "\n",
        "    # 1) Coerce numeric types and calculate age\n",
        "    listings_lr['year'] = pd.to_numeric(listings_lr['year'], errors='coerce')\n",
        "    listings_lr['odometer'] = pd.to_numeric(listings_lr['odometer'], errors='coerce')\n",
        "    listings_lr[\"listed_price\"] = pd.to_numeric(listings_lr[\"listed_price\"], errors='coerce')\n",
        "    listings_lr['age'] = 2026 - listings_lr['year']\n",
        "\n",
        "    # 2) One-hot encode model_gen\n",
        "    listings_lr[\"model_gen\"] = listings_lr[\"model_gen\"].astype(str)\n",
        "    dummies = pd.get_dummies(listings_lr[\"model_gen\"], prefix=\"mg_\", prefix_sep=\"\")\n",
        "\n",
        "    # remove base category \"civic_9\" if it exists\n",
        "    base_col = \"civic_9\"\n",
        "    if base_col in dummies.columns:\n",
        "        dummies = dummies.drop(columns=[base_col])\n",
        "\n",
        "    listings_lr = pd.concat([listings_lr, dummies], axis=1)\n",
        "\n",
        "    # 3) Build X, y & keep mask\n",
        "    predictor_cols = ['age', 'odometer'] + list(dummies.columns)\n",
        "    X = listings_lr[predictor_cols].astype(float)\n",
        "    y = listings_lr[\"listed_price\"].astype(float)\n",
        "\n",
        "    keep = X.notna().all(axis=1) & y.notna()\n",
        "\n",
        "    X_keep = X.loc[keep]\n",
        "    y_keep = y.loc[keep]\n",
        "\n",
        "    # 4) Scale predictors\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_keep)\n",
        "\n",
        "    # 5) Fit Huber Regression\n",
        "    huber = HuberRegressor(max_iter=1000, epsilon=1.5)\n",
        "    huber.fit(X_scaled, y_keep)\n",
        "\n",
        "    # 6) Predict & store results\n",
        "    pred = huber.predict(X_scaled)\n",
        "    listings_lr.loc[keep, \"market_value\"] = pred\n",
        "    listings_lr.loc[keep, \"value_diff\"] = pred - listings_lr.loc[keep, \"listed_price\"]\n",
        "\n",
        "    # 7) Recover coefficients on the original (unscaled) feature scale\n",
        "    coef_scaled = huber.coef_\n",
        "    mu = scaler.mean_\n",
        "    sigma = scaler.scale_\n",
        "\n",
        "    original_intercept = huber.intercept_ - np.sum(coef_scaled * (mu / sigma))\n",
        "    original_coefs = coef_scaled / sigma\n",
        "\n",
        "    coef_unscaled = pd.Series(\n",
        "        np.concatenate([[original_intercept], original_coefs]),\n",
        "        index=[\"intercept\"] + predictor_cols\n",
        "    )\n",
        "\n",
        "    listings_lr = listings_lr.loc[:, ~listings_lr.columns.str.startswith(\"mg_\")]\n",
        "\n",
        "    return listings_lr, coef_unscaled"
      ],
      "id": "23f91c4e",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working"
      ],
      "metadata": {
        "id": "d3osOXG0ExJz"
      },
      "id": "d3osOXG0ExJz"
    },
    {
      "cell_type": "code",
      "source": [
        "clients=[\n",
        "    {\n",
        "        \"client\":\"anita_c\",\n",
        "        \"max_listing_price\":13500,\n",
        "        \"max_odometer\":160,\n",
        "        \"model_gens\":[\n",
        "            \"3_2\",\n",
        "            \"civic_\",\n",
        "            \"jazz_3\",\n",
        "            \"i30_\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"client\":\"magesh_t\",\n",
        "        \"max_listing_price\":13500,\n",
        "        \"max_odometer\":160,\n",
        "        \"model_gens\":[\n",
        "            \"3_2\",\n",
        "            \"civic_\",\n",
        "            \"i30_\"\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "Lp-q0rytSS9Q"
      },
      "id": "Lp-q0rytSS9Q",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_lookup = pd.read_csv(\"/content/drive/Shareddrives/market_analysis_v2/gen_lookup.csv\")\n",
        "listings = pd.read_csv(\"/content/drive/Shareddrives/market_analysis_v2/listings.csv\")"
      ],
      "metadata": {
        "id": "J37vmfyrnkAQ"
      },
      "id": "J37vmfyrnkAQ",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_new_listings(listings, gen_lookup)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiTdqt2VxNCE",
        "outputId": "e22adc04-f5e4-4d2b-a8d9-3af85b8a9028"
      },
      "id": "BiTdqt2VxNCE",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/carsales (3).csv    \t n_new=3   \t n_updated=3 \t n_unchanged=2 \t Tot 8\n",
            "/content/carsales (4).csv    \t n_new=7   \t n_updated=3 \t n_unchanged=1 \t Tot 11\n",
            "/content/carsales (1).csv    \t n_new=2   \t n_updated=2 \t n_unchanged=10 \t Tot 14\n",
            "/content/carsales (2).csv    \t n_new=18   \t n_updated=0 \t n_unchanged=3 \t Tot 21\n",
            "/content/carsales.csv    \t n_new=0   \t n_updated=0 \t n_unchanged=8 \t Tot 8\n",
            "/content/carsales (6).csv    \t n_new=4   \t n_updated=0 \t n_unchanged=11 \t Tot 15\n",
            "/content/carsales (5).csv    \t n_new=6   \t n_updated=1 \t n_unchanged=14 \t Tot 22\n",
            "/content/facebook (1).csv    \t n_new=20   \t n_updated=0 \t n_unchanged=4 \t Tot 24\n",
            "/content/facebook (3).csv    \t n_new=18   \t n_updated=0 \t n_unchanged=11 \t Tot 29\n",
            "/content/facebook.csv    \t n_new=6   \t n_updated=2 \t n_unchanged=25 \t Tot 33\n",
            "/content/facebook (2).csv    \t n_new=41   \t n_updated=1 \t n_unchanged=9 \t Tot 51\n",
            "\t \t \t \t tot_new=125 \t tot_updated=12\t tot_unchanged=98 tot_tot=236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "6d173a02",
        "outputId": "4be29f8c-da75-4c37-ffda-47cdd59aef92"
      },
      "source": [
        "# Add new listings to listings dataframe\n",
        "\n",
        "# Call the function to integrate the listings\n",
        "listings1 = integrate_listings(listings, gen_lookup)\n",
        "\n",
        "print(\"\\nFirst 5 rows of the newly created listings_1:\")\n",
        "display(listings1.head())"
      ],
      "id": "6d173a02",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final listings_1 DataFrame has 1115 unique listings after merging and de-duplication.\n",
            "\n",
            "First 5 rows of the newly created listings_1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  href   make       model  \\\n",
              "950  https://www.carsales.com.au/cars/details/2004-...  honda        jazz   \n",
              "959  https://www.carsales.com.au/cars/details/2004-...  honda        jazz   \n",
              "945  https://www.carsales.com.au/cars/details/2005-...  honda        jazz   \n",
              "967  https://www.carsales.com.au/cars/details/2005-...  honda        jazz   \n",
              "369  https://www.carsales.com.au/cars/details/2006-...  honda  accordeuro   \n",
              "\n",
              "    date_scraped     model_gen  year  gen  seller_type  listed_price  \\\n",
              "950   2025-12-04        jazz_1  2004    1  Dealer used          4999   \n",
              "959   2025-12-04        jazz_1  2004    1  Dealer used          6995   \n",
              "945   2025-12-04        jazz_1  2005    1      Private          5900   \n",
              "967   2025-12-04        jazz_1  2005    1      Private          7000   \n",
              "369   2025-12-04  accordeuro_1  2006    1  Dealer used          8990   \n",
              "\n",
              "     odometer location                trim  \n",
              "950       183      NaN          VTi Auto F  \n",
              "959       173      NaN   VTi-S Auto F MY05  \n",
              "945       270      NaN     GLi Auto F MY05  \n",
              "967       121      NaN     VTi Auto F MY05  \n",
              "369       135      NaN  Luxury Auto F MY06  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a60d801-e10b-413a-aa88-8dd1aa8b036c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>href</th>\n",
              "      <th>make</th>\n",
              "      <th>model</th>\n",
              "      <th>date_scraped</th>\n",
              "      <th>model_gen</th>\n",
              "      <th>year</th>\n",
              "      <th>gen</th>\n",
              "      <th>seller_type</th>\n",
              "      <th>listed_price</th>\n",
              "      <th>odometer</th>\n",
              "      <th>location</th>\n",
              "      <th>trim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>950</th>\n",
              "      <td>https://www.carsales.com.au/cars/details/2004-...</td>\n",
              "      <td>honda</td>\n",
              "      <td>jazz</td>\n",
              "      <td>2025-12-04</td>\n",
              "      <td>jazz_1</td>\n",
              "      <td>2004</td>\n",
              "      <td>1</td>\n",
              "      <td>Dealer used</td>\n",
              "      <td>4999</td>\n",
              "      <td>183</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VTi Auto F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>https://www.carsales.com.au/cars/details/2004-...</td>\n",
              "      <td>honda</td>\n",
              "      <td>jazz</td>\n",
              "      <td>2025-12-04</td>\n",
              "      <td>jazz_1</td>\n",
              "      <td>2004</td>\n",
              "      <td>1</td>\n",
              "      <td>Dealer used</td>\n",
              "      <td>6995</td>\n",
              "      <td>173</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VTi-S Auto F MY05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>945</th>\n",
              "      <td>https://www.carsales.com.au/cars/details/2005-...</td>\n",
              "      <td>honda</td>\n",
              "      <td>jazz</td>\n",
              "      <td>2025-12-04</td>\n",
              "      <td>jazz_1</td>\n",
              "      <td>2005</td>\n",
              "      <td>1</td>\n",
              "      <td>Private</td>\n",
              "      <td>5900</td>\n",
              "      <td>270</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GLi Auto F MY05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>https://www.carsales.com.au/cars/details/2005-...</td>\n",
              "      <td>honda</td>\n",
              "      <td>jazz</td>\n",
              "      <td>2025-12-04</td>\n",
              "      <td>jazz_1</td>\n",
              "      <td>2005</td>\n",
              "      <td>1</td>\n",
              "      <td>Private</td>\n",
              "      <td>7000</td>\n",
              "      <td>121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VTi Auto F MY05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>https://www.carsales.com.au/cars/details/2006-...</td>\n",
              "      <td>honda</td>\n",
              "      <td>accordeuro</td>\n",
              "      <td>2025-12-04</td>\n",
              "      <td>accordeuro_1</td>\n",
              "      <td>2006</td>\n",
              "      <td>1</td>\n",
              "      <td>Dealer used</td>\n",
              "      <td>8990</td>\n",
              "      <td>135</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Luxury Auto F MY06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a60d801-e10b-413a-aa88-8dd1aa8b036c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a60d801-e10b-413a-aa88-8dd1aa8b036c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a60d801-e10b-413a-aa88-8dd1aa8b036c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-efb0a226-80ad-427c-a678-55a9f487cba7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-efb0a226-80ad-427c-a678-55a9f487cba7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-efb0a226-80ad-427c-a678-55a9f487cba7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29cd174a"
      },
      "source": [
        "listings_lr, coefficients = apply_regression(listings1)"
      ],
      "id": "29cd174a",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listings_lr.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "_88cTpl702Qb",
        "outputId": "5427c3f7-357c-4edf-caa5-95aa473fafdb"
      },
      "id": "_88cTpl702Qb",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1503307397.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1503307397.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    listings_lr[].head()\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}