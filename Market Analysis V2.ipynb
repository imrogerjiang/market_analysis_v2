{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "ae2ea91a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2ea91a",
        "outputId": "dba1c4ad-aa78-4761-863b-8483f06f9fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import Dict, Optional, List\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "sys.path.append('/content/drive/Shareddrives/market_analysis_v2/scripts')\n",
        "# from clean_cs import *\n",
        "# from clean_fb import *\n",
        "# from constants_and_helpers import *\n",
        "from enrich import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script Functions"
      ],
      "metadata": {
        "id": "1DYdMWKeEnLW"
      },
      "id": "1DYdMWKeEnLW"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "# --- Carsales/General Scrapes (CS) Constants ---\n",
        "YEAR_MIN, YEAR_MAX = 1980, 2035\n",
        "ORDER: List[str] = ['href', 'year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']\n",
        "\n",
        "YEAR_RE  = r'\\b(19[89]\\d|20[0-3]\\d)\\b'\n",
        "PRICE_RE = r'^\\s*(?:AU\\$|\\$)?\\s*[\\d,]+(?:\\.\\d{2})?\\b'\n",
        "ODOM_RE  = r'^\\s*\\d+(?:,?\\d{3})*(?:K)?\\s*km?\\s*$'\n",
        "URL_RE   = r'^(?:https?://|www\\.)'\n",
        "TX, SELLER = {'automatic', 'manual'}, {'private', 'dealer used'}\n",
        "\n",
        "THRESH: Dict[str, float] = {\n",
        "    'year_make_model': 0.50,\n",
        "    \"listed_price\":           0.60,\n",
        "    'transmission':    0.80,\n",
        "    'odometer':        0.60,\n",
        "    'seller_type':     0.70,\n",
        "}\n",
        "\n",
        "# --- Facebook Marketplace (FB) Constants ---\n",
        "FB_ORDER: List[str] = ['href', 'year_make_model', 'listed_price', 'odometer', 'location']\n",
        "THRESH_FB: Dict[str, float] = {\n",
        "    'href':            0.80,\n",
        "    'year_make_model': 0.50,\n",
        "    'listed_price':    0.60,\n",
        "    'odometer':        0.60,\n",
        "    'location':        0.40,\n",
        "}\n",
        "\n",
        "# --- Predicates (Validation Rules) ---\n",
        "def _ratio(mask: pd.Series) -> float:\n",
        "    return float(mask.mean()) if len(mask) else 0.0\n",
        "\n",
        "def _yr_ok(s: pd.Series) -> pd.Series:\n",
        "    years = pd.to_numeric(s.astype(str).str.extract(YEAR_RE, expand=False), errors='coerce')\n",
        "    return years.between(YEAR_MIN, YEAR_MAX)\n",
        "\n",
        "PRED = {\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    \"listed_price\":           lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'transmission':    lambda s: s.astype(str).str.strip().str.lower().isin(TX),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "    'seller_type':     lambda s: s.astype(str).str.strip().str.lower().isin(SELLER),\n",
        "}\n",
        "\n",
        "PRED_FB = {\n",
        "    'href':            lambda s: s.astype(str).str.contains(URL_RE, case=False, na=False),\n",
        "    'year_make_model': lambda s: s.astype(str).pipe(_yr_ok) & s.astype(str).str.contains(r'[A-Za-z]', na=False),\n",
        "    'listed_price':    lambda s: s.astype(str).str.match(PRICE_RE, na=False),\n",
        "    'odometer':        lambda s: s.astype(str).str.match(ODOM_RE, flags=re.I, na=False),\n",
        "}\n",
        "\n",
        "# --- Core Identification Functions ---\n",
        "def identify_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identifies and maps raw DataFrame columns to canonical Carsales/General columns.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in ORDER}\n",
        "\n",
        "    href_col = cols[0]\n",
        "\n",
        "    # Exclude URL-like columns from other detection logic\n",
        "    url_ratio = {c: _ratio(df[c].astype(str).str.contains(URL_RE, case=False, na=False)) for c in cols}\n",
        "    urlish = {c for c, r in url_ratio.items() if r >= 0.50}\n",
        "    blocked = {href_col} | urlish\n",
        "\n",
        "    remaining = [c for c in cols if c not in blocked]\n",
        "    picks = {t: None for t in PRED}\n",
        "\n",
        "    for t in PRED:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED[t](df[c])) for c in remaining}\n",
        "        best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "        if best_score >= THRESH[t]:\n",
        "            picks[t] = best_col\n",
        "            remaining.remove(best_col)\n",
        "\n",
        "    trim_col = None\n",
        "    ymm = picks.get('year_make_model')\n",
        "    if ymm in cols:\n",
        "        i = cols.index(ymm)\n",
        "        if i + 1 < len(cols):\n",
        "            trim_col = cols[i + 1]\n",
        "\n",
        "    return {'href': href_col, **picks, 'trim': trim_col}\n",
        "\n",
        "def identify_fb_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    \"\"\"Identifies and maps raw DataFrame columns to canonical Facebook Marketplace columns.\"\"\"\n",
        "    cols = list(df.columns)\n",
        "    if not cols:\n",
        "        return {k: None for k in FB_ORDER}\n",
        "\n",
        "    picks = {t: None for t in FB_ORDER}\n",
        "    remaining = set(cols)\n",
        "\n",
        "    # Prioritize 'href' column identification\n",
        "    href_scores = {c: _ratio(PRED_FB['href'](df[c])) for c in remaining}\n",
        "    best_href_col, best_href_score = None, 0.0\n",
        "    if href_scores:\n",
        "        best_href_col, best_href_score = max(href_scores.items(), key=lambda kv: kv[1])\n",
        "\n",
        "    if best_href_score >= THRESH_FB['href']:\n",
        "        picks['href'] = best_href_col\n",
        "        remaining.remove(best_href_col)\n",
        "    elif 'x1i10hfl href' in remaining and _ratio(PRED_FB['href'](df['x1i10hfl href'])) >= THRESH_FB['href']:\n",
        "        # Fallback to specific column name if it exists and matches pattern well\n",
        "        picks['href'] = 'x1i10hfl href'\n",
        "        remaining.remove('x1i10hfl href')\n",
        "\n",
        "    # Identify 'year_make_model', 'listed_price', 'odometer'\n",
        "    for t in ['year_make_model', 'listed_price', 'odometer']:\n",
        "        if not remaining:\n",
        "            break\n",
        "        scores = {c: _ratio(PRED_FB[t](df[c])) for c in remaining}\n",
        "        if scores:\n",
        "            best_col, best_score = max(scores.items(), key=lambda kv: kv[1])\n",
        "            if best_score >= THRESH_FB[t]:\n",
        "                picks[t] = best_col\n",
        "                remaining.remove(best_col)\n",
        "\n",
        "    # Assign 'location', often found in column 'c' or as the last remaining column\n",
        "    if picks['location'] is None:\n",
        "        if 'c' in remaining:\n",
        "            picks['location'] = 'c'\n",
        "            remaining.remove('c')\n",
        "        elif len(remaining) == 1:\n",
        "            picks['location'] = remaining.pop()\n",
        "\n",
        "    return picks"
      ],
      "metadata": {
        "id": "gECV1vdedUm0"
      },
      "id": "gECV1vdedUm0",
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa5c70d3"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "def clean_cs(df: pd.DataFrame, save_raw: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Business Logic for clean_cs function:\n",
        "\n",
        "    This function processes raw DataFrame outputs from Carsales/General web scrapes to standardize\n",
        "    and clean vehicle listing data into a consistent format for analysis.\n",
        "\n",
        "    Key steps and business rules:\n",
        "    1.  **Raw Data Preservation (Optional):** If `save_raw` is True, the original DataFrame\n",
        "        is saved to a timestamped CSV, and a 'raw' column (filename) is added to the output.\n",
        "    2.  **Column Identification:** Dynamically maps raw DataFrame columns to canonical names\n",
        "        ('href', 'year_make_model', 'listed_price', 'odometer', etc.) using `identify_columns`.\n",
        "    3.  **Data Extraction & Standardization:**\n",
        "        *   Cleans 'href' by removing query parameters.\n",
        "        *   Splits 'year_make_model' into 'year', 'make', and 'model'; converts 'year' to integer.\n",
        "        *   Converts 'listed_price' and 'odometer' to integer, removing non-numeric characters.\n",
        "        *   Transforms 'odometer' values from 'km' to '000 km' (e.g., 180,000 km -> 180).\n",
        "    4.  **Output Structure:** Returns a DataFrame with a standardized set of columns for consistency.\n",
        "    \"\"\"\n",
        "    raw_col_value = None\n",
        "    if save_raw:\n",
        "        raw_data_dir = 'data/raws'\n",
        "        os.makedirs(raw_data_dir, exist_ok=True)\n",
        "        timestamp = datetime.now()\n",
        "        raw_filename = ''\n",
        "        while True:\n",
        "            raw_filename = os.path.join(raw_data_dir, f\"raw_carsales_data_{timestamp.strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "            if not os.path.exists(raw_filename):\n",
        "                break\n",
        "            timestamp += timedelta(seconds=1)\n",
        "        df.to_csv(raw_filename, index=False)\n",
        "        raw_col_value = os.path.basename(raw_filename)\n",
        "\n",
        "    if 'identify_columns' not in globals():\n",
        "        raise NameError(\"Function 'identify_columns' not found. Please ensure 'constants_and_helpers.py' or cell 'gECV1vdedUm0' has been executed.\")\n",
        "\n",
        "    mapping = identify_columns(df)\n",
        "    out = pd.DataFrame()\n",
        "\n",
        "    if mapping['href'] is not None:\n",
        "        out['href'] = df[mapping['href']]\n",
        "    for col in ['year_make_model', 'trim', \"listed_price\", 'transmission', 'odometer', 'seller_type']:\n",
        "        src = mapping.get(col)\n",
        "        if src is not None:\n",
        "            out[col] = df[src]\n",
        "\n",
        "    if save_raw and raw_col_value:\n",
        "        out['raw'] = raw_col_value\n",
        "\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_cols = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        if 0 in split_cols.columns:\n",
        "            out['year'] = pd.to_numeric(\n",
        "                split_cols[0].astype(str).str.replace(r'[^\\d]', '', regex=True),\n",
        "                errors='coerce'\n",
        "            ).astype('Int64')\n",
        "        else:\n",
        "            out['year'] = pd.NA\n",
        "        out['make'] = split_cols[1] if 1 in split_cols.columns else pd.NA\n",
        "        out['model'] = split_cols[2] if 2 in split_cols.columns else pd.NA\n",
        "    else:\n",
        "        out[['year', 'make', 'model']] = pd.NA\n",
        "\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            out[col] = pd.to_numeric(\n",
        "                out[col].astype(str).str.replace(r'[^\\d]', '', regex=True),\n",
        "                errors='coerce'\n",
        "            ).astype('Int64')\n",
        "\n",
        "    if 'odometer' in out.columns:\n",
        "        out['odometer'] = out['odometer'] // 1000\n",
        "\n",
        "    final_cols = ['href', 'year', 'make', 'model', \"listed_price\", 'trim', 'odometer', 'seller_type']\n",
        "    if save_raw:\n",
        "        final_cols.insert(0, 'raw')\n",
        "    return out[[c for c in final_cols if c in out.columns]]"
      ],
      "execution_count": 152,
      "outputs": [],
      "id": "aa5c70d3"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_fb(df: pd.DataFrame, save_raw: bool = False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Business Logic for clean_fb function:\n",
        "\n",
        "    This function processes raw DataFrame outputs from Facebook Marketplace scrapes to standardize\n",
        "    and clean vehicle listing data into a consistent format for analysis.\n",
        "\n",
        "    Key steps and business rules:\n",
        "    1.  **Raw Data Preservation (Optional):** If `save_raw` is True, the original DataFrame\n",
        "        is saved to a timestamped CSV, and a 'raw' column (filename) is added to the output.\n",
        "    2.  **Column Identification:** Dynamically maps raw DataFrame columns to canonical names\n",
        "        ('href', 'year_make_model', 'listed_price', 'odometer', 'location') using `identify_fb_columns`.\n",
        "    3.  **Data Extraction & Standardization:**\n",
        "        *   Cleans 'href' by removing query parameters.\n",
        "        *   Splits 'year_make_model' into 'year', 'make', and 'model'; converts 'year' to integer.\n",
        "        *   Converts 'listed_price' and 'odometer' to integer, removing non-numeric characters.\n",
        "        *   Filters out listings with 'listed_price' explicitly marked as \"free\".\n",
        "    4.  **Data Quality Filtering:** Drops rows with missing (`pd.NA`) values in critical columns\n",
        "        ('listed_price', 'odometer', 'year') to ensure data integrity. Also removes listings\n",
        "        with a placeholder 'listed_price' of 12345.\n",
        "    5.  **Output Structure:** Returns a DataFrame with a standardized set of columns for consistency.\n",
        "    \"\"\"\n",
        "    raw_col_value = None\n",
        "    if save_raw:\n",
        "        raw_data_dir = 'data/raws'\n",
        "        os.makedirs(raw_data_dir, exist_ok=True)\n",
        "        timestamp = datetime.now()\n",
        "        raw_filename = ''\n",
        "        while True:\n",
        "            raw_filename = os.path.join(raw_data_dir, f\"raw_facebook_data_{timestamp.strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "            if not os.path.exists(raw_filename):\n",
        "                break\n",
        "            timestamp += timedelta(seconds=1)\n",
        "        df.to_csv(raw_filename, index=False)\n",
        "        raw_col_value = os.path.basename(raw_filename)\n",
        "\n",
        "    if 'identify_fb_columns' not in globals():\n",
        "        raise NameError(\"Function 'identify_fb_columns' not found. Please ensure 'constants_and_helpers.py' or cell 'gECV1vdedUm0' has been executed.\")\n",
        "\n",
        "    mapping = identify_fb_columns(df)\n",
        "    out = pd.DataFrame()\n",
        "    for canonical_col, src_col in mapping.items():\n",
        "        if src_col is not None and src_col in df.columns:\n",
        "            out[canonical_col] = df[src_col]\n",
        "\n",
        "    if save_raw and raw_col_value:\n",
        "        out['raw'] = raw_col_value\n",
        "\n",
        "    if 'year_make_model' in out.columns:\n",
        "        split_df = out['year_make_model'].astype(str).str.split(expand=True, n=2)\n",
        "        if 0 in split_df.columns:\n",
        "            out['year'] = split_df[0].astype(str).str.replace(r'[^\\d]', '', regex=True).replace('', pd.NA).astype(float).astype('Int64')\n",
        "        else:\n",
        "            out['year'] = pd.NA\n",
        "        out['make'] = split_df[1] if 1 in split_df.columns else pd.NA\n",
        "        out['model'] = split_df[2] if 2 in split_df.columns else pd.NA\n",
        "    else:\n",
        "        out[['year', 'make', 'model']] = pd.NA\n",
        "\n",
        "    if 'href' in out.columns:\n",
        "        out['href'] = out['href'].astype(str).str.split('?').str[0]\n",
        "\n",
        "    for col in [\"listed_price\", 'odometer']:\n",
        "        if col in out.columns:\n",
        "            if col == 'listed_price':\n",
        "                out = out[out[col].astype(str).str.lower() != \"free\"]\n",
        "            out[col] = pd.to_numeric(\n",
        "                out[col].astype(str).str.replace(r'[^\\d]', '', regex=True),\n",
        "                errors='coerce'\n",
        "            ).astype('Int64')\n",
        "\n",
        "    cols_to_check_for_na = []\n",
        "    if 'listed_price' in out.columns: cols_to_check_for_na.append('listed_price')\n",
        "    if 'odometer' in out.columns: cols_to_check_for_na.append('odometer')\n",
        "    if 'year' in out.columns: cols_to_check_for_na.append('year')\n",
        "\n",
        "    if cols_to_check_for_na:\n",
        "        out = out.dropna(subset=cols_to_check_for_na)\n",
        "\n",
        "    if 'listed_price' in out.columns:\n",
        "        out = out[out[\"listed_price\"] != 12345]\n",
        "        out = out[out[\"listed_price\"] < 3000]\n",
        "\n",
        "    final_columns = ['href', 'year', 'make', 'model', \"listed_price\", 'odometer', 'location']\n",
        "    if save_raw:\n",
        "        final_columns.insert(0, 'raw')\n",
        "    return out[[c for c in final_columns if c in out.columns]]"
      ],
      "metadata": {
        "id": "N5MMcCRVEbDl"
      },
      "id": "N5MMcCRVEbDl",
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import Dict, Optional, List\n",
        "\n",
        "def enrich_df(df: pd.DataFrame, gen_lookup: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Final clean after clean_cs or clean_fb, including generation assignment.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame to enrich.\n",
        "        gen_lookup (pd.DataFrame): A lookup table for car generations.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The enriched DataFrame.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Add date_scraped ---\n",
        "    df[\"date_scraped\"] = pd.Timestamp.now().normalize()\n",
        "\n",
        "    # --- 2. Normalise make & model ---\n",
        "    for col in [\"make\", \"model\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = (\n",
        "                df[col]\n",
        "                .astype(str)\n",
        "                .str.lower()\n",
        "                .str.replace(r\"[^a-z0-9]+\", \"\", regex=True)\n",
        "            )\n",
        "\n",
        "    # --- 3. Ensure year is numeric ---\n",
        "    if \"year\" in df.columns:\n",
        "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # --- 4. Assign generation manually (no merge, no year_start/year_end contamination) ---\n",
        "    df[\"gen\"] = pd.NA\n",
        "\n",
        "    for idx, row in gen_lookup.iterrows():\n",
        "        mask = (\n",
        "            (df[\"make\"] == row[\"make\"]) &\n",
        "            (df[\"model\"] == row[\"model\"]) &\n",
        "            (df[\"year\"].between(row[\"year_start\"], row[\"year_end\"], inclusive=\"both\"))\n",
        "        )\n",
        "        df.loc[mask, \"gen\"] = row[\"gen\"]\n",
        "\n",
        "    df[\"gen\"] = df[\"gen\"].astype(\"Int64\")\n",
        "\n",
        "    # --- 5. Create model_gen ---\n",
        "    df[\"model_gen\"] = df.apply(\n",
        "        lambda r: f\"{r['model']}_{r['gen']}\" if pd.notna(r[\"gen\"]) else None,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "9EoYNNjuIakO"
      },
      "id": "9EoYNNjuIakO",
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working"
      ],
      "metadata": {
        "id": "d3osOXG0ExJz"
      },
      "id": "d3osOXG0ExJz"
    },
    {
      "cell_type": "code",
      "source": [
        "clients=[\n",
        "    {\n",
        "        \"client\":\"anita_c\",\n",
        "        \"max_listing_price\":13500,\n",
        "        \"max_odometer\":160000,\n",
        "        \"model_gens\":[\n",
        "            \"3_2\",\n",
        "            \"civic_\",\n",
        "            \"jazz_3\",\n",
        "            \"i30_\"\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"client\":\"magesh_t\",\n",
        "        \"max_listing_price\":13500,\n",
        "        \"max_odometer\":160000,\n",
        "        \"model_gens\":[\n",
        "            \"3_2\",\n",
        "            \"civic_\",\n",
        "            \"i30_\"\n",
        "        ]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "Lp-q0rytSS9Q"
      },
      "id": "Lp-q0rytSS9Q",
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many listings are new, updated, or duplicate?\n",
        "\n",
        "total_new, total_updated, total_dups = 0,0,0\n",
        "\n",
        "cs_files = glob.glob('/content/carsales*.csv')\n",
        "fb_files = glob.glob('/content/facebook*.csv')\n",
        "for file_path in cs_files+fb_files:\n",
        "    file_name = os.path.basename(file_path)\n",
        "\n",
        "    # a. Load the CSV file into a pandas DataFrame\n",
        "    df_raw = pd.read_csv(file_path)\n",
        "\n",
        "    # b. Clean the loaded DataFrame using the clean_cs() function\n",
        "    df_cleaned = clean_cs(df_raw)\n",
        "\n",
        "    # c. Perform a left merge of df_cleaned with the listings DataFrame\n",
        "    df_comparison = pd.merge(\n",
        "        df_cleaned,\n",
        "        listings,\n",
        "        on='href',\n",
        "        how='left',\n",
        "        suffixes=('_new', '_existing')\n",
        "    )\n",
        "\n",
        "    # d. Identify new listings\n",
        "    new_listings_df = df_comparison[df_comparison['listed_price_existing'].isnull()]\n",
        "    n_new = len(new_listings_df)\n",
        "\n",
        "    # e. Identify matched listings\n",
        "    matched_listings_df = df_comparison[df_comparison['listed_price_existing'].notnull()]\n",
        "\n",
        "    # f. From matched_listings, identify updated listings\n",
        "    updated_listings_df = matched_listings_df[\n",
        "        matched_listings_df['listed_price_new'] != matched_listings_df['listed_price_existing']\n",
        "    ]\n",
        "    n_updated = len(updated_listings_df)\n",
        "\n",
        "    # g. From matched_listings, identify duplicate listings\n",
        "    duplicate_listings_df = matched_listings_df[\n",
        "        matched_listings_df['listed_price_new'] == matched_listings_df['listed_price_existing']\n",
        "    ]\n",
        "    n_duplicate = len(duplicate_listings_df)\n",
        "\n",
        "    # h. Calculate total listings for the current file\n",
        "    n_total_listings = len(df_cleaned)\n",
        "\n",
        "    # i. Print the comparison result for the current file\n",
        "    print(f\"{file_name}    \\t New {n_new}   \\t Update {n_updated} \\t Dups {n_duplicate} \\t Tot {n_total_listings}\")\n",
        "\n",
        "    # j. Add counts to total counters\n",
        "    total_new += n_new\n",
        "    total_updated += n_updated\n",
        "    total_dups += n_duplicate\n",
        "\n",
        "print(f\"Total New: {total_new} \\t Total Updated: {total_updated} \\t Total Duplicate: {total_dups}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNc8XIRTM7oa",
        "outputId": "355557fe-293f-4c97-94e4-8cdfcd7ce05f"
      },
      "id": "uNc8XIRTM7oa",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "carsales (1).csv    \t New 2   \t Update 12 \t Dups 0 \t Tot 14\n",
            "carsales (3).csv    \t New 3   \t Update 5 \t Dups 0 \t Tot 8\n",
            "carsales (4).csv    \t New 7   \t Update 4 \t Dups 0 \t Tot 11\n",
            "carsales.csv    \t New 0   \t Update 8 \t Dups 0 \t Tot 8\n",
            "carsales (2).csv    \t New 18   \t Update 3 \t Dups 0 \t Tot 21\n",
            "carsales (6).csv    \t New 4   \t Update 11 \t Dups 0 \t Tot 15\n",
            "carsales (5).csv    \t New 6   \t Update 16 \t Dups 0 \t Tot 22\n",
            "facebook (1).csv    \t New 21   \t Update 0 \t Dups 4 \t Tot 25\n",
            "facebook.csv    \t New 6   \t Update 2 \t Dups 25 \t Tot 33\n",
            "facebook (3).csv    \t New 18   \t Update 0 \t Dups 11 \t Tot 29\n",
            "facebook (2).csv    \t New 43   \t Update 1 \t Dups 9 \t Tot 53\n",
            "Total New: 128 \t Total Updated: 62 \t Total Duplicate: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_lookup = pd.read_csv(\"/content/drive/Shareddrives/market_analysis_v2/gen_lookup.csv\")\n",
        "listings = pd.read_csv(\"/content/drive/Shareddrives/market_analysis_v2/listings.csv\")"
      ],
      "metadata": {
        "id": "J37vmfyrnkAQ"
      },
      "id": "J37vmfyrnkAQ",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8pffOKFUhxP"
      },
      "id": "R8pffOKFUhxP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}